{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7c48494",
   "metadata": {},
   "source": [
    "Computer Vision for employees' performance detection by Nursan Omarov."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65fd15e",
   "metadata": {},
   "source": [
    "Abstract:\n",
    "\n",
    "Employee productivity is a critical determinant of organizational success, yet traditional performance monitoring methods are often subjective, intermittent, and disruptive. This paper presents a novel approach utilizing YOLOv10 (You Only Look Once, version 10) for real-time, non-intrusive performance detection in office environments, specifically tailored to enhance productivity. We introduce a newly curated dataset designed to capture key performance indicators (KPIs) through computer vision analysis, such as task engagement (e.g., active desk work, collaboration, breaks), posture analysis, and equipment utilization. The YOLOv10 architecture is leveraged for its state-of-the-art balance of speed and accuracy, enabling robust object and behavior localization necessary for reliable, low-latency deployment. The trained model successfully analyzes visual data streams to generate objective, quantifiable metrics regarding employee workflow and engagement. Preliminary results demonstrate the system's ability to accurately detect and classify performance-related actions, providing actionable insights for management to identify workflow bottlenecks, optimize office layout, and offer targeted support and training. This research offers a scalable and privacy-aware computer vision framework that transforms raw video data into strategic organizational intelligence, moving beyond subjective assessment to drive measurable improvements in workplace productivity.\n",
    "Inspired by the source: [https://github.com/THU-MIG/yolov10.git]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf73b80",
   "metadata": {},
   "source": [
    "Step 01: Prepare your GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac3ce241",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\"nvidia-smi\" �� ���� ����७��� ��� ���譥�\n",
      "��������, �ᯮ��塞�� �ணࠬ��� ��� ������ 䠩���.\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a7e56f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa3af1e",
   "metadata": {},
   "source": [
    "Step 02: Download dataset you prepared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7549120a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: roboflow in c:\\conda\\lib\\site-packages (1.2.9)\n",
      "Requirement already satisfied: certifi in c:\\conda\\lib\\site-packages (from roboflow) (2024.8.30)\n",
      "Requirement already satisfied: idna==3.7 in c:\\conda\\lib\\site-packages (from roboflow) (3.7)\n",
      "Requirement already satisfied: cycler in c:\\conda\\lib\\site-packages (from roboflow) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\conda\\lib\\site-packages (from roboflow) (1.4.4)\n",
      "Requirement already satisfied: matplotlib in c:\\conda\\lib\\site-packages (from roboflow) (3.9.2)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\conda\\lib\\site-packages (from roboflow) (1.26.4)\n",
      "Requirement already satisfied: opencv-python-headless==4.10.0.84 in c:\\conda\\lib\\site-packages (from roboflow) (4.10.0.84)\n",
      "Requirement already satisfied: Pillow>=7.1.2 in c:\\conda\\lib\\site-packages (from roboflow) (11.3.0)\n",
      "Requirement already satisfied: pi-heif<2 in c:\\conda\\lib\\site-packages (from roboflow) (1.1.0)\n",
      "Requirement already satisfied: pillow-avif-plugin<2 in c:\\conda\\lib\\site-packages (from roboflow) (1.5.2)\n",
      "Requirement already satisfied: python-dateutil in c:\\conda\\lib\\site-packages (from roboflow) (2.9.0.post0)\n",
      "Requirement already satisfied: python-dotenv in c:\\conda\\lib\\site-packages (from roboflow) (0.21.0)\n",
      "Requirement already satisfied: requests in c:\\conda\\lib\\site-packages (from roboflow) (2.32.3)\n",
      "Requirement already satisfied: six in c:\\conda\\lib\\site-packages (from roboflow) (1.16.0)\n",
      "Requirement already satisfied: urllib3>=1.26.6 in c:\\conda\\lib\\site-packages (from roboflow) (2.2.3)\n",
      "Requirement already satisfied: tqdm>=4.41.0 in c:\\conda\\lib\\site-packages (from roboflow) (4.66.5)\n",
      "Requirement already satisfied: PyYAML>=5.3.1 in c:\\conda\\lib\\site-packages (from roboflow) (6.0.1)\n",
      "Requirement already satisfied: requests-toolbelt in c:\\conda\\lib\\site-packages (from roboflow) (1.0.0)\n",
      "Requirement already satisfied: filetype in c:\\conda\\lib\\site-packages (from roboflow) (1.2.0)\n",
      "Requirement already satisfied: colorama in c:\\conda\\lib\\site-packages (from tqdm>=4.41.0->roboflow) (0.4.6)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\conda\\lib\\site-packages (from matplotlib->roboflow) (1.3.3)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\conda\\lib\\site-packages (from matplotlib->roboflow) (4.51.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\conda\\lib\\site-packages (from matplotlib->roboflow) (24.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\conda\\lib\\site-packages (from matplotlib->roboflow) (3.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\conda\\lib\\site-packages (from requests->roboflow) (3.3.2)\n",
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Dataset Version Zip in Employee-Performance-Monitoring-4 to yolov8:: 100%|██████████| 172424/172424 [01:09<00:00, 2473.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting Dataset Version Zip to Employee-Performance-Monitoring-4 in yolov8:: 100%|██████████| 5368/5368 [00:06<00:00, 816.51it/s] \n"
     ]
    }
   ],
   "source": [
    "!pip install roboflow\n",
    "\n",
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"DY0PJbVE10rxuOzeA7Uj\")\n",
    "project = rf.workspace(\"project-x2uaa\").project(\"employee-performance-monitoring\")\n",
    "version = project.version(4)\n",
    "dataset = version.download(\"yolov8\")\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92cb3cd",
   "metadata": {},
   "source": [
    "Step 03: Install YOLOv10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2682f693",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\CONDA\\Lib\\site-packages\\~-mpy.libs'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\CONDA\\Lib\\site-packages\\~-mpy'.\n",
      "  You can safely remove it manually.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "gensim 4.3.3 requires numpy<2.0,>=1.18.5, but you have numpy 2.2.6 which is incompatible.\n",
      "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.2.6 which is incompatible.\n",
      "streamlit 1.37.1 requires pillow<11,>=7.1.0, but you have pillow 11.3.0 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install -q ultralytics\n",
    "!pip install -q supervision\n",
    "!pip install -q git+https://github.com/THU-MIG/yolov10.git\n",
    "!pip install -q huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99c12599",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy==1.26.4\n",
      "  Using cached numpy-1.26.4-cp312-cp312-win_amd64.whl.metadata (61 kB)\n",
      "Using cached numpy-1.26.4-cp312-cp312-win_amd64.whl (15.5 MB)\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.2.6\n",
      "    Uninstalling numpy-2.2.6:\n",
      "      Successfully uninstalled numpy-2.2.6\n",
      "Successfully installed numpy-1.26.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\CONDA\\Lib\\site-packages\\~~mpy.libs'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\CONDA\\Lib\\site-packages\\~~mpy'.\n",
      "  You can safely remove it manually.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
      "streamlit 1.37.1 requires pillow<11,>=7.1.0, but you have pillow 11.3.0 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy==1.26.4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e5257a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLOv10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f159cc8d",
   "metadata": {},
   "source": [
    "Step 04: Download pre-trained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01100948",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q safetensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51681347",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLOv10\n",
    "model = YOLOv10.from_pretrained(\"jameslahm/yolov10n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c785f89",
   "metadata": {},
   "source": [
    "Step 05: Inference with Pre-trained COCO Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22a208c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading http://images.cocodataset.org/val2017/000000039769.jpg to '000000039769.jpg'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 169k/169k [00:00<00:00, 192kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image 1/1 c:\\Users\\user\\Documents\\Computer_vision_for_employees'_performance_surveilance\\000000039769.jpg: 480x640 2 cats, 1 couch, 2 remotes, 124.1ms\n",
      "Speed: 5.2ms preprocess, 124.1ms inference, 14.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "source = 'http://images.cocodataset.org/val2017/000000039769.jpg'\n",
    "results = model.predict(source=source, save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "218d6c61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 40.3199,  72.7351, 175.6783, 118.8764],\n",
      "        [ 10.6486,  55.6572, 317.5321, 464.6425],\n",
      "        [344.7463,  25.0566, 640.0000, 371.2010],\n",
      "        [333.9006,  76.7366, 370.0751, 189.8246],\n",
      "        [  2.1036,   2.1936, 639.4435, 480.0000]])\n",
      "tensor([0.9079, 0.8805, 0.8733, 0.7435, 0.3595])\n",
      "tensor([65., 15., 15., 65., 57.])\n"
     ]
    }
   ],
   "source": [
    "print(results[0].boxes.xyxy)\n",
    "print(results[0].boxes.conf)\n",
    "print(results[0].boxes.cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42f876fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 2 cats, 1 couch, 2 remotes, 163.3ms\n",
      "Speed: 8.2ms preprocess, 163.3ms inference, 10.8ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'supervision' has no attribute 'BoundingBoxAnnotator'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m results \u001b[38;5;241m=\u001b[39m model(image)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m      8\u001b[0m detections \u001b[38;5;241m=\u001b[39m sv\u001b[38;5;241m.\u001b[39mDetections\u001b[38;5;241m.\u001b[39mfrom_ultralytics(results)\n\u001b[1;32m----> 9\u001b[0m bounding_box_annotator \u001b[38;5;241m=\u001b[39m sv\u001b[38;5;241m.\u001b[39mBoundingBoxAnnotator()\n\u001b[0;32m     11\u001b[0m label_annotator \u001b[38;5;241m=\u001b[39m sv\u001b[38;5;241m.\u001b[39mLabelAnnotator()\n\u001b[0;32m     12\u001b[0m annotated_image \u001b[38;5;241m=\u001b[39m bounding_box_annotator\u001b[38;5;241m.\u001b[39mannotate(\n\u001b[0;32m     13\u001b[0m     scene \u001b[38;5;241m=\u001b[39m image, detections \u001b[38;5;241m=\u001b[39m detections\n\u001b[0;32m     14\u001b[0m )\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'supervision' has no attribute 'BoundingBoxAnnotator'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import supervision as sv\n",
    "from ultralytics import YOLOv10\n",
    "\n",
    "model = model\n",
    "image = cv2.imread(\"000000039769.jpg\")\n",
    "results = model(image)[0]\n",
    "detections = sv.Detections.from_ultralytics(results)\n",
    "bounding_box_annotator = sv.BoundingBoxAnnotator()\n",
    "\n",
    "label_annotator = sv.LabelAnnotator()\n",
    "annotated_image = bounding_box_annotator.annotate(\n",
    "    scene = image, detections = detections\n",
    ")\n",
    "annotated_image = label_annotator.annotate(\n",
    "    scene = annotated_image, detections=detections\n",
    ")\n",
    "\n",
    "sv.plot_image(annotated_image)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16e1cdc",
   "metadata": {},
   "source": [
    "Step 06: Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453608f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!yolo task=detect mode=train epochs=25 batch=8 plots=True \\\n",
    "model=model\n",
    "data={\"./Employee-Performance-Monitoring-4/data.yaml\"}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
